# Default values for daytona.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Global configuration
global:
  imageRegistry: ""
  imagePullSecrets: []
  storageClass: ""
  namespace: "" # If not set, will default to Release.Namespace

# Base domain Daytona
baseDomain: "daytona.example.com"

# Service-specific configurations
services:
  api:
    # Image configuration
    image:
      registry: docker.io
      repository: daytonaio/daytona-api
      tag: "v0.132.0-rc.1-k8s" # Will default to Chart.AppVersion
      pullPolicy: IfNotPresent
    # Service configuration
    service:
      type: ClusterIP
      port: 3000
      annotations: {}
    # Ingress configuration
    ingress:
      enabled: true
      className: "nginx"
      annotations: {}
        # nginx.ingress.kubernetes.io/ssl-redirect: "true"
      # If not set, defaults to .Values.baseDomain
      hostname: ""
      path: "/"
      pathType: "Prefix"
      # Additional hosts to be added to the ingress record
      extraHosts: []
      # Additional paths to be added to the ingress under the main host
      extraPaths: []
      # Additional TLS configuration for additional hostnames
      extraTls: []
      # Additional ingress rules
      extraRules: []
      # Enable TLS
      tls: true
      # Custom TLS secret name (optional)
      # If set, uses this existing secret instead of auto-generating the name
      # The secret must already exist in the cluster or be managed externally
      tlsSecretName: ""
      # Enable self-signed certificates
      selfSigned: false
      # Custom TLS certificates as secrets
      # NOTE: 'key' and 'certificate' are expected in PEM format
      # NOTE: 'name' should match the secretName used in ingress TLS configuration
      # NOTE: The certificate MUST include both the base domain and its wildcard (*.baseDomain) in the Subject Alternative Names (SAN)
      #       since both API and Proxy ingresses use the same TLS secret covering: daytona.example.com and *.daytona.example.com
      # If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
      # If it is not set and you're NOT using cert-manager either, set selfSigned: true to generate self-signed certificates (includes wildcard)
      # It is also possible to create and manage the certificates outside of this helm chart
      # e.g:
      # secrets:
      #   - name: daytona.example.com-tls
      #     key: |-
      #       -----BEGIN RSA PRIVATE KEY-----
      #       ...
      #       -----END RSA PRIVATE KEY-----
      #     certificate: |-
      #       -----BEGIN CERTIFICATE-----
      #       ...
      #       -----END CERTIFICATE-----
      secrets: []
    # Environment variables (can be overridden via Helm values)
    env:
      # Application configuration
      ENVIRONMENT: "production"
      PORT: "3000"

      # OIDC configuration
      OIDC_CLIENT_ID: ""
      OIDC_ISSUER_BASE_URL: ""
      PUBLIC_OIDC_DOMAIN: ""
      OIDC_AUDIENCE: ""
      SKIP_USER_EMAIL_VERIFICATION: "false"

      # Workspace configuration
      DEFAULT_SNAPSHOT_IMAGE_NAME: "daytonaio/sandbox:0.5.1-slim"
      DEFAULT_SNAPSHOT_NAME: "default-snapshot"
      RUNNER_MANAGER_API_KEY: "runner_manager_secret_key"
      # Auto-generated as "https://{{.Values.baseDomain}}/dashboard" if not set or empty
      DASHBOARD_URL: ""
      # Auto-generated as "https://{{.Values.baseDomain}}" if not set or empty
      DASHBOARD_BASE_API_URL: ""

      # Registry configuration (Harbor)
      # If Harbor is enabled, will use Harbor ingress URL and credentials. If external registry is to be used, then disable Harbor in this chart and set the external registry URL and credentials here.
      # TRANSIENT_REGISTRY_URL: ""
      # TRANSIENT_REGISTRY_ADMIN: ""
      # TRANSIENT_REGISTRY_PASSWORD: ""
      # TRANSIENT_REGISTRY_PROJECT_ID: ""
      # INTERNAL_REGISTRY_URL: ""
      # INTERNAL_REGISTRY_ADMIN: ""
      # INTERNAL_REGISTRY_PASSWORD: ""
      # INTERNAL_REGISTRY_PROJECT_ID: ""

      # SMTP configuration
      SMTP_HOST: ""
      SMTP_PORT: ""
      SMTP_USER: ""
      SMTP_PASSWORD: ""
      SMTP_SECURE: ""
      SMTP_EMAIL_FROM: ""

      # S3 configuration
      # NOTE: Currently we dont suppoert Declarative Builder File System Operations (https://www.daytona.io/docs/en/declarative-builder/) and Volumes (https://www.daytona.io/docs/en/volumes/) feature in self-hosted daytona.
      # If MinIO is enabled, will use MinIO service URL and credentials. If external S3 storage is used, then disable MinIO in this chart and set the external S3 storage URL and credentials here.
      # S3_ENDPOINT: ""
      # S3_STS_ENDPOINT: ""
      # S3_REGION: ""
      # S3_ACCESS_KEY: ""
      # S3_SECRET_KEY: ""
      # S3_DEFAULT_BUCKET: ""
      # S3_ACCOUNT_ID: ""
      # S3_ROLE_NAME: ""

    # Extra environment variables (for valueFrom or additional custom vars)
    # Use this for environment variables that need valueFrom (secretKeyRef, configMapKeyRef)
    # or additional custom environment variables beyond the standard env section
    # Example:
    # extraEnv:
    #   - name: CUSTOM_SECRET
    #     valueFrom:
    #       secretKeyRef:
    #         name: my-secret
    #         key: my-key
    #   - name: CUSTOM_CONFIGMAP
    #     valueFrom:
    #       configMapKeyRef:
    #         name: my-configmap
    #         key: my-key
    #   - name: CUSTOM_VALUE
    #     value: "custom-value"
    extraEnv: []

    # Resource limits and requests
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi
    # Node selector
    nodeSelector: {}
    # Tolerations
    tolerations: []
    # Affinity
    affinity: {}
    # Annotations
    annotations: {}
    # Pod annotations
    podAnnotations: {}
    # Replica count
    replicaCount: 1
    # Horizontal Pod Autoscaler configuration
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 10
      targetCPUUtilizationPercentage: 80
      # targetMemoryUtilizationPercentage: 80
      # Custom metrics (optional)
      # metrics: []
      # Scaling behavior (optional)
      # behavior:
      #   scaleDown:
      #     stabilizationWindowSeconds: 300
      #     policies:
      #     - type: Percent
      #       value: 50
      #       periodSeconds: 15
      #   scaleUp:
      #     stabilizationWindowSeconds: 0
      #     policies:
      #     - type: Percent
      #       value: 100
      #       periodSeconds: 15
      #     - type: Pods
      #       value: 4
      #       periodSeconds: 15
      #     selectPolicy: Max
      annotations: {}
    # Service account
    serviceAccount:
      create: true
      annotations: {}
      name: ""

  proxy:
    # Image configuration
    image:
      registry: docker.io
      repository: daytonaio/daytona-proxy
      tag: "v0.139.0"
      pullPolicy: IfNotPresent
    # Service configuration
    service:
      type: ClusterIP
      port: 4000
      annotations: {}
    # Ingress configuration
    # NOTE: Proxy ingress uses wildcard host (*.baseDomain) to support
    # unique subdomains per sandbox. Each sandbox requires its own subdomain,
    # so the wildcard pattern is hardcoded in the template (e.g., *.daytona.example.com).
    # Base domain (daytona.example.com) routes to API, all subdomains route to Proxy.
    # Both ingresses use the same TLS secret that covers base domain + wildcard.
    ingress:
      enabled: true
      className: "nginx"
      annotations: {}
        #nginx.ingress.kubernetes.io/ssl-redirect: "true"
        #nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
        #nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
      # Proxy ingress uses wildcard pattern (*.baseDomain) - hostname setting is ignored
      # All subdomains of baseDomain route to proxy service
      hostname: ""
      path: "/"
      pathType: "Prefix"
      # Additional hosts to be added to the ingress record
      # NOTE: Wildcard host (*.baseDomain) is already hardcoded in the template, no need to add it here
      extraHosts: []
      # Additional paths to be added to the ingress under the main host
      extraPaths: []
      # Additional TLS configuration for additional hostnames
      extraTls: []
      # Additional ingress rules
      extraRules: []
      # Enable TLS
      tls: true
      # Custom TLS secret name (optional)
      # If set, uses this existing secret instead of auto-generating the name
      # The secret must already exist in the cluster or be managed externally
      tlsSecretName: ""
      # Enable self-signed certificates
      selfSigned: false
      # Custom TLS certificates as secrets
      # NOTE: 'key' and 'certificate' are expected in PEM format
      # NOTE: 'name' should match the secretName used in ingress TLS configuration
      # NOTE: The certificate MUST include both the base domain and its wildcard (*.baseDomain) in the Subject Alternative Names (SAN)
      #       since both API and Proxy ingresses use the same TLS secret covering: daytona.example.com and *.daytona.example.com
      # If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
      # If it is not set and you're NOT using cert-manager either, set selfSigned: true to generate self-signed certificates (includes wildcard)
      # It is also possible to create and manage the certificates outside of this helm chart
      # e.g:
      # secrets:
      #   - name: daytona.example.com-tls
      #     key: |-
      #       -----BEGIN RSA PRIVATE KEY-----
      #       ...
      #       -----END RSA PRIVATE KEY-----
      #     certificate: |-
      #       -----BEGIN CERTIFICATE-----
      #       ...
      #       -----END CERTIFICATE-----
      secrets: []
    # Environment variables
    env:
      # Proxy port container service will listen on. Defaults to 4000 if not set.
      PROXY_PORT: ""
      # Auto-generated as "proxy.{{.Values.baseDomain}}:{{PROXY_PORT}}" if not set or empty
      PROXY_DOMAIN: ""
      PROXY_API_KEY: "super_secret_key"
      PROXY_PROTOCOL: http
      OIDC_CLIENT_SECRET: ""
    # Resource limits and requests
    resources:
      limits:
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 64Mi
    # Node selector
    nodeSelector: {}
    # Tolerations
    tolerations: []
    # Affinity
    affinity: {}
    # Annotations
    annotations: {}
    # Pod annotations
    podAnnotations: {}
    # Replica count
    replicaCount: 1
    # Horizontal Pod Autoscaler configuration
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 10
      targetCPUUtilizationPercentage: 80
      # targetMemoryUtilizationPercentage: 80
      # Custom metrics (optional)
      # metrics: []
      # Scaling behavior (optional)
      # behavior:
      #   scaleDown:
      #     stabilizationWindowSeconds: 300
      #     policies:
      #     - type: Percent
      #       value: 50
      #       periodSeconds: 15
      #   scaleUp:
      #     stabilizationWindowSeconds: 0
      #     policies:
      #     - type: Percent
      #       value: 100
      #       periodSeconds: 15
      #     - type: Pods
      #       value: 4
      #       periodSeconds: 15
      #     selectPolicy: Max
      annotations: {}
    # Service account
    serviceAccount:
      create: true
      annotations: {}
      name: ""

  sshGateway:
    enabled: true
    # Image configuration
    image:
      registry: docker.io
      repository: daytonaio/daytona-ssh-gateway
      tag: "" # Will default to Chart.AppVersion
      pullPolicy: IfNotPresent
    # Service configuration
    service:
      type: LoadBalancer
      port: 2222
      annotations: {}
    # Set api key for ssh gateway. This key is used to authenticate the ssh gateway against api
    apiKey: supersecretapikey
    # Generate ssh keys to be used for the ssh gateway. These keys are stored in the secret and used to authenticate the ssh gateway. Generate keys using ssh-keygen (ssh-keygen -t ed25519 -f gateway_host_key -N "") and store them as base64 (cat gateway_host_key | base64 -w 0) values here. You will need 2 groups of keys - one for the client and one for the gateway.
    sshKeys:
      privClientSSHKey: "LS0tLS1CRUdJTiBPUEVOU1NIIFBSSVZBVEUgS0VZLS0tLS0KYjNCbGJuTnphQzFyWlhrdGRqRUFBQUFBQkc1dmJtVUFBQUFFYm05dVpRQUFBQUFBQUFBQkFBQUFNd0FBQUF0emMyZ3RaVwpReU5UVXhPUUFBQUNDK0FvVlE2TkhWUXJkUzA2V0lvMHAwamZWOXVQQUp0QUZMWGlBUlRIdC9lUUFBQUpEWmREVzMyWFExCnR3QUFBQXR6YzJndFpXUXlOVFV4T1FBQUFDQytBb1ZRNk5IVlFyZFMwNldJbzBwMGpmVjl1UEFKdEFGTFhpQVJUSHQvZVEKQUFBRUM2ZlVsOHlDdW1rQ3N3djF4N2tQQ0hSZS9iM242M3c0R3RCU3VScXpBblRiNENoVkRvMGRWQ3QxTFRwWWlqU25TTgo5WDI0OEFtMEFVdGVJQkZNZTM5NUFBQUFDbU5zYVdWdWRDMXJaWGtCQWdNPQotLS0tLUVORCBPUEVOU1NIIFBSSVZBVEUgS0VZLS0tLS0K"
      pubClientSSHKey: "c3NoLWVkMjU1MTkgQUFBQUMzTnphQzFsWkRJMU5URTVBQUFBSUw0Q2hWRG8wZFZDdDFMVHBZaWpTblNOOVgyNDhBbTBBVXRlSUJGTWUzOTUgY2xpZW50LWtleQo="
      privGatewaySSHKey: "LS0tLS1CRUdJTiBPUEVOU1NIIFBSSVZBVEUgS0VZLS0tLS0KYjNCbGJuTnphQzFyWlhrdGRqRUFBQUFBQkc1dmJtVUFBQUFFYm05dVpRQUFBQUFBQUFBQkFBQUFNd0FBQUF0emMyZ3RaVwpReU5UVXhPUUFBQUNETnFRUEczaTdJc3lndlNOcnFEWUtsVFluaUpMRTEwSExOaGFZTkZUY1ZGUUFBQUpDVVI2dERsRWVyClF3QUFBQXR6YzJndFpXUXlOVFV4T1FBQUFDRE5xUVBHM2k3SXN5Z3ZTTnJxRFlLbFRZbmlKTEUxMEhMTmhhWU5GVGNWRlEKQUFBRUNHRHR2RTA3Zk1HeWxkeVJmdHhiUEFzUlQ4VmppdjFZajVmL01vR2pMT0RNMnBBOGJlTHNpektDOUkydW9OZ3FWTgppZUlrc1RYUWNzMkZwZzBWTnhVVkFBQUFDbk5sY25abGNpMXJaWGtCQWdNPQotLS0tLUVORCBPUEVOU1NIIFBSSVZBVEUgS0VZLS0tLS0K"
    env:
      SSH_GATEWAY_PORT: "2222"
      # Auto-generated as "ssh.{{.Values.baseDomain}}" if not set or empty
      SSH_GATEWAY_HOST: ""
    # Resource limits and requests
    resources:
      limits:
        cpu: 200m
        memory: 256Mi
      requests:
        cpu: 10m
        memory: 64Mi
    # Node selector
    nodeSelector: {}
    # Tolerations
    tolerations: []
    # Affinity
    affinity: {}
    # Annotations
    annotations: {}
    # Pod annotations
    podAnnotations: {}
    # Replica count
    replicaCount: 1
    # Service account
    serviceAccount:
      create: true
      annotations: {}
      name: ""

  runnermanager:
    enabled: true
    # Image configuration
    image:
      registry: docker.io
      repository: daytonaio/daytona-runner-manager
      tag: "v0.132.0-rc.1-k8s" # Will default to Chart.AppVersion
      pullPolicy: IfNotPresent
    # Service configuration
    service:
      type: ClusterIP
      port: 3010
      annotations: {}
    # Environment variables
    env:
      # API Configuration
      API_PORT: "3010"
      # API Authentication - Generate a secure token with: openssl rand -base64 32
      API_TOKEN: "runner_manager_secret_key"
      # System API Token
      SYSTEM_API_TOKEN: "system_api_token"
      # Provider Configuration - Options: kubernetes, k8s, aws
      PROVIDER_TYPE: "kubernetes"
      # Kubernetes Provider - Namespace for placeholder pods (defaults to deployment namespace)
      #PROVIDER_NAMESPACE: "default"
      # Logging Configuration - Options: debug, info, warn, error, fatal, panic
      LOG_LEVEL: "info"
      # Pod Wait Timeout - Timeout in seconds for waiting for pods to be scheduled to nodes
      POD_WAIT_TIMEOUT: "600"
      # Kubeconfig Path (Optional - for local development)
      # If not set, will use in-cluster configuration
      KUBECONFIG_PATH: ""
      API_KEY: "secret_api_key"
      # Auto-generated as "https://{{.Values.baseDomain}}/api" if not set or empty
      SERVER_URL: "http://daytona-api:3000/api"
      REGION_ID: "us"
      ENVIRONMENT: "development"
      # Runner API Port
      RUNNER_API_PORT: "3000"
    # Extra environment variables (for valueFrom or additional custom vars)
    extraEnv: []
    # Resource limits and requests
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi
    # Node selector
    nodeSelector: {}
    # Tolerations
    tolerations: []
    # Affinity
    affinity: {}
    # Annotations
    annotations: {}
    # Pod annotations
    podAnnotations: {}
    # Service account
    serviceAccount:
      create: true
      annotations: {}
      name: ""
    # RBAC configuration
    rbac:
      create: true

  runner:
    enabled: true
    # Image configuration
    image:
      registry: docker.io
      repository: daytonaio/daytona-runner
      tag: "v0.132.0-rc.1-k8s" # Will default to Chart.AppVersion
      pullPolicy: IfNotPresent
    # ServiceAccount configuration
    serviceAccount:
      create: true
      annotations: {}
      name: ""
    # Environment variables
    env:
      # Configuration
      API_PORT: "3000"
      ENVIRONMENT: "production"
      CONTAINER_RUNTIME: ""
      LOG_FILE_PATH: "/home/daytona/runner/runner.log"
      LOG_LEVEL: "info"
      SSH_GATEWAY_ENABLE: "true"
      SSH_GATEWAY_PORT: "2220"
      RESOURCE_LIMITS_DISABLED: "false"
      CACHE_RETENTION_DAYS: "7"
      DAEMON_START_TIMEOUT_SEC: "30"
      SANDBOX_START_TIMEOUT_SEC: "60"
      # Secrets
      DAYTONA_API_URL: "http://daytona-api:3000/api"
      SERVER_URL: "http://daytona-api:3000/api"
      API_TOKEN: "secret_api_token"
      SYSTEM_API_TOKEN: "system_api_token"
      AWS_REGION: ""
      AWS_ENDPOINT_URL: ""
      AWS_ACCESS_KEY_ID: ""
      AWS_SECRET_ACCESS_KEY: ""
      AWS_DEFAULT_BUCKET: ""
      # The same value as the .Values.services.sshGateway.sshKeys.pubClientSSHKey
      SSH_PUBLIC_KEY: "c3NoLWVkMjU1MTkgQUFBQUMzTnphQzFsWkRJMU5URTVBQUFBSUw0Q2hWRG8wZFZDdDFMVHBZaWpTblNOOVgyNDhBbTBBVXRlSUJGTWUzOTUgY2xpZW50LWtleQo="
    # Resource limits and requests
    resources:
      limits:
        cpu: 2000m
        memory: 4Gi
      requests:
        cpu: 1000m
        memory: 2Gi
    # Affinity (specific to runner, fallback to global)
    affinity: {}
    # Pod annotations
    podAnnotations: {}
    # Host aliases for registry resolution
    hostAliases: []
    # Example:
    # hostAliases:
    #   - ip: "10.0.0.1"
    #     hostnames:
    #       - "registry.local"
    #       - "minio.local"
    # Registry proxy sidecar configuration (optional)
    registryProxy:
      enabled: false
      image: "alpine/socat:1.7.4.4-r0"
      listenPort: 5000
      targetHost: "registry.external.com"
      targetPort: 443
    # Docker installer sidecar configuration (optional)
    dockerInstaller:
      enabled: true
      image: "ubuntu:22.04"
      xfsStorageSize: "50G"
      # Airgapped mode - use pre-packaged dependencies instead of downloading from internet
      airgapped:
        enabled: false
        # Image containing pre-packaged .deb files and dependencies
        # The image should have packages at /packages/packages.tar.gz
        packagesImage: "daytonaio/daytona-runner-packages:v0.0.1"
    # Extra environment variables (for valueFrom or additional custom vars)
    extraEnv: []

# Global node selector (fallback)
nodeSelector: {}

# Global tolerations (fallback)
tolerations: []

# Global affinity (fallback)
affinity: {}

# Pod security context
podSecurityContext:
  fsGroup: 2000

# Container security context
securityContext:
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: false
  runAsNonRoot: false
  runAsUser: 0

## Daytona External Database Configuration
## All of these values are only used if `postgresql.enabled=false`
externalDatabase:
  host: "daytona-postgresql"
  port: 5432
  name: "daytona"
  user: "user"
  # Enable TLS/SSL for database connection
  enableTLS: true
  # Allow self-signed or internal certificates
  allowSelfSignedCert: true
  # Ignored if existingSecret is provided
  password: "pass"
  # If existingSecret is provided, it should contain key: database-password
  existingSecret: ""

# External Redis Configuration
# All of these values are only used if `redis.enabled=false`
externalRedis:
  host: "daytona-redis-master"
  port: 6379
  tls: false
  # Ignored if existingSecret is provided
  password: ""
  # If existingSecret is provided, it should contain key: redis-password
  existingSecret: ""

# Dex configuration (simple IdP for testing)
dex:
  enabled: true
  image:
    registry: docker.io
    repository: dexidp/dex
    tag: "v2.42.0"
  service:
    port: 5556
  persistence:
    enabled: true
    size: 1Gi
    storageClass: ""
  # Ingress configuration
  ingress:
    enabled: true
    className: "nginx"
    annotations: {}
      #nginx.ingress.kubernetes.io/ssl-redirect: "true"
    # If not set, defaults to "dex.{{.Values.baseDomain}}"
    hostname: ""
    path: "/"
    pathType: "Prefix"
    # Additional hosts to be added to the ingress record
    extraHosts: []
    # Additional paths to be added to the ingress under the main host
    extraPaths: []
    # Additional TLS configuration for additional hostnames
    extraTls: []
    # Additional ingress rules
    extraRules: []
    # Enable TLS
    tls: true
    # Custom TLS secret name (optional)
    # If set, uses this existing secret instead of auto-generating the name
    # The secret must already exist in the cluster or be managed externally
    tlsSecretName: ""
    # Enable self-signed certificates
    selfSigned: false
    # Custom TLS certificates as secrets
    # NOTE: 'key' and 'certificate' are expected in PEM format
    # NOTE: 'name' should match the secretName used in ingress TLS configuration
    # NOTE: The certificate can use the same secret as API/Proxy (covers base domain + wildcard)
    #       or a separate certificate for dex subdomain
    # If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
    # If it is not set and you're NOT using cert-manager either, set selfSigned: true to generate self-signed certificates
    # It is also possible to create and manage the certificates outside of this helm chart
    # e.g:
    # secrets:
    #   - name: dex.daytona.example.com-tls
    #     key: |-
    #       -----BEGIN RSA PRIVATE KEY-----
    #       ...
    #       -----END RSA PRIVATE KEY-----
    #     certificate: |-
    #       -----BEGIN CERTIFICATE-----
    #       ...
    #       -----END CERTIFICATE-----
    secrets: []
  config:
    # Issuer URL (auto-generated if not set)
    issuer: ""
    # OIDC client ID
    clientId: "daytona"
    # Client name
    clientName: "Daytona"
    # Redirect URIs for OIDC client (auto-generated if not set)
    # Defaults to:
    # - http://[fullname]-api:[api-port]
    # - http://[fullname]-api:[api-port]/api/oauth2-redirect.html
    # - http://localhost:8080 (for port-forward)
    # - http://localhost:8080/api/oauth2-redirect.html (for port-forward)
    # - http://localhost:3009/callback
    # - http://[fullname]-proxy:[proxy-port]/callback
    redirectURIs: []
    # Static passwords (for development/testing)
    # Password hash can be generated with: echo password | htpasswd -BinC 10 admin | cut -d: -f2
    # default username/password is admin/password
    staticPasswords:
      - email: "dev@daytona.io"
        username: "admin"
        password: "$2y$10$pQ8jbpk6RWHx/uYJtDey.uCTzVl2ZXg569tp63PE9uisbCYzoARW6"
        userID: "1234"

# Redis configuration
redis:
  enabled: true
  global:
    security:
      allowInsecureImages: true
  image:
    registry: docker.io
    repository: bitnamilegacy/redis
  auth:
    enabled: false
  persistence:
    enabled: true
    size: 1Gi
  containerPorts:
    redis: 6379
  replica:
    replicaCount: 0

# PgAdmin subchart configuration
pgadmin4:
  enabled: true
  env:
    email: "dev@daytona.io"
    password: "SuperSecrets"
  service:
    type: ClusterIP
    port: 80
  persistentVolume:
    enabled: true
    size: 1Gi
  serverDefinitions:
    enabled: true
    resourceType: ConfigMap
    servers:
      daytona:
        Name: "Daytona"
        Group: "Servers"
        Host: "daytona-postgresql"
        Port: 5432
        MaintenanceDB: "postgres"
        Username: "user"
        Password: "pass"

# Harbor subchart configuration
harbor:
  enabled: true
  # Harbor configuration
  expose:
    type: ingress
    tls:
      enabled: true
      certSource: secret
      secret:
        secretName: "daytona.example.com-tls"
    ingress:
      className: nginx
      annotations:
        nginx.ingress.kubernetes.io/ssl-redirect: "true"
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
      hosts:
        core: "harbor.daytona.example.com"
  existingSecretAdminPassword: ""
  existingSecretAdminPasswordKey: HARBOR_ADMIN_PASSWORD
  harborAdminPassword: "Harbor12345"
  externalURL: "https://harbor.daytona.example.com"
  updateStrategy:
    type: Recreate
  # The persistence is enabled by default and a default StorageClass
  # is needed in the k8s cluster to provision volumes dynamically.
  # Specify another StorageClass in the "storageClass" or set "existingClaim"
  # if you already have existing persistent volumes to use
  #
  # For storing images and charts, you can also use "azure", "gcs", "s3",
  # "swift" or "oss". Set it in the "imageChartStorage" section
  persistence:
    enabled: true
    # Setting it to "keep" to avoid removing PVCs during a helm delete
    # operation. Leaving it empty will delete PVCs after the chart deleted
    # (this does not apply for PVCs that are created for internal database
    # and redis components, i.e. they are never deleted automatically)
    resourcePolicy: "keep"
    persistentVolumeClaim:
      registry:
        # Use the existing PVC which must be created manually before bound,
        # and specify the "subPath" if the PVC is shared with other components
        existingClaim: ""
        # Specify the "storageClass" used to provision the volume. Or the default
        # StorageClass will be used (the default).
        # Set it to "-" to disable dynamic provisioning
        storageClass: ""
        subPath: ""
        accessMode: ReadWriteOnce
        size: 5Gi
        annotations: {}
      jobservice:
        jobLog:
          existingClaim: ""
          storageClass: ""
          subPath: ""
          accessMode: ReadWriteOnce
          size: 1Gi
          annotations: {}
      # If external database is used, the following settings for database will
      # be ignored
      database:
        existingClaim: ""
        storageClass: ""
        subPath: ""
        accessMode: ReadWriteOnce
        size: 1Gi
        annotations: {}
      # If external Redis is used, the following settings for Redis will
      # be ignored
      redis:
        existingClaim: ""
        storageClass: ""
        subPath: ""
        accessMode: ReadWriteOnce
        size: 1Gi
        annotations: {}
      trivy:
        existingClaim: ""
        storageClass: ""
        subPath: ""
        accessMode: ReadWriteOnce
        size: 5Gi
        annotations: {}
    # Define which storage backend is used for registry to store
    # images and charts. Refer to
    # https://github.com/distribution/distribution/blob/release/2.8/docs/configuration.md#storage
    # for the detail.
    imageChartStorage:
      # Specify whether to disable `redirect` for images and chart storage, for
      # backends which not supported it (such as using minio for `s3` storage type), please disable
      # it. To disable redirects, simply set `disableredirect` to `true` instead.
      # Refer to
      # https://github.com/distribution/distribution/blob/release/2.8/docs/configuration.md#redirect
      # for the detail.
      disableredirect: false
      # Specify the "caBundleSecretName" if the storage service uses a self-signed certificate.
      # The secret must contain keys named "ca.crt" which will be injected into the trust store
      # of registry's containers.
      # caBundleSecretName:

      # Specify the type of storage: "filesystem", "azure", "gcs", "s3", "swift",
      # "oss" and fill the information needed in the corresponding section. The type
      # must be "filesystem" if you want to use persistent volumes for registry
      type: filesystem
      filesystem:
        rootdirectory: /storage
        #maxthreads: 100
      azure:
        accountname: accountname
        accountkey: base64encodedaccountkey
        container: containername
        #realm: core.windows.net
        # To use existing secret, the key must be AZURE_STORAGE_ACCESS_KEY
        existingSecret: ""
      gcs:
        bucket: bucketname
        # The base64 encoded json file which contains the key
        encodedkey: base64-encoded-json-key-file
        #rootdirectory: /gcs/object/name/prefix
        #chunksize: "5242880"
        # To use existing secret, the key must be GCS_KEY_DATA
        existingSecret: ""
        useWorkloadIdentity: false
      s3:
        # Set an existing secret for S3 accesskey and secretkey
        # keys in the secret should be REGISTRY_STORAGE_S3_ACCESSKEY and REGISTRY_STORAGE_S3_SECRETKEY for registry
        #existingSecret: ""
        region: us-west-1
        bucket: bucketname
        #accesskey: awsaccesskey
        #secretkey: awssecretkey
        #regionendpoint: http://myobjects.local
        #encrypt: false
        #keyid: mykeyid
        #secure: true
        #skipverify: false
        #v4auth: true
        #chunksize: "5242880"
        #rootdirectory: /s3/object/name/prefix
        #storageclass: STANDARD
        #multipartcopychunksize: "33554432"
        #multipartcopymaxconcurrency: 100
        #multipartcopythresholdsize: "33554432"
  trivy:
    enabled: false
  database:
    # if external database is used, set "type" to "external"
    # and fill the connection information in "external" section
    type: internal
    internal:
      image:
        repository: goharbor/harbor-db
        tag: v2.14.0
      # set the service account to be used, default if left empty
      serviceAccountName: ""
      # mount the service account token
      automountServiceAccountToken: false
      # resources:
      #  requests:
      #    memory: 256Mi
      #    cpu: 100m
      # The timeout used in livenessProbe; 1 to 5 seconds
      livenessProbe:
        timeoutSeconds: 1
      # The timeout used in readinessProbe; 1 to 5 seconds
      readinessProbe:
        timeoutSeconds: 1
      extraEnvVars: []
      nodeSelector: {}
      tolerations: []
      affinity: {}
      ## The priority class to run the pod as
      priorityClassName:
      # containers to be run before the controller's container starts.
      extrInitContainers: []
      # Example:
      #
      # - name: wait
      #   image: busybox
      #   command: [ 'sh', '-c', "sleep 20" ]
      # The initial superuser password for internal database
      password: "changeit"
      # The size limit for Shared memory, pgSQL use it for shared_buffer
      # More details see:
      # https://github.com/goharbor/harbor/issues/15034
      shmSizeLimit: 512Mi
      initContainer:
        migrator: {}
        # resources:
        #  requests:
        #    memory: 128Mi
        #    cpu: 100m
        permissions: {}
        # resources:
        #  requests:
        #    memory: 128Mi
        #    cpu: 100m
    external:
      host: "192.168.0.1"
      port: "5432"
      username: "user"
      password: "password"
      coreDatabase: "registry"
      # if using existing secret, the key must be "password"
      existingSecret: ""
      # "disable" - No SSL
      # "require" - Always SSL (skip verification)
      # "verify-ca" - Always SSL (verify that the certificate presented by the
      # server was signed by a trusted CA)
      # "verify-full" - Always SSL (verify that the certification presented by the
      # server was signed by a trusted CA and the server host name matches the one
      # in the certificate)
      sslmode: "disable"
    # The maximum number of connections in the idle connection pool per pod (core+exporter).
    # If it <=0, no idle connections are retained.
    maxIdleConns: 100
    # The maximum number of open connections to the database per pod (core+exporter).
    # If it <= 0, then there is no limit on the number of open connections.
    # Note: the default number of connections is 1024 for harbor's postgres.
    maxOpenConns: 900
    ## Additional deployment annotations
    podAnnotations: {}
    ## Additional deployment labels
    podLabels: {}
  redis:
    # if external Redis is used, set "type" to "external"
    # and fill the connection information in "external" section
    type: internal
    internal:
      image:
        repository: goharbor/redis-photon
        tag: v2.14.0
      # set the service account to be used, default if left empty
      serviceAccountName: ""
      # mount the service account token
      automountServiceAccountToken: false
      # resources:
      #  requests:
      #    memory: 256Mi
      #    cpu: 100m
      extraEnvVars: []
      nodeSelector: {}
      tolerations: []
      affinity: {}
      ## The priority class to run the pod as
      priorityClassName:
      # containers to be run before the controller's container starts.
      initContainers: []
      # Example:
      #
      # - name: wait
      #   image: busybox
      #   command: [ 'sh', '-c', "sleep 20" ]
      # # jobserviceDatabaseIndex defaults to "1"
      # # registryDatabaseIndex defaults to "2"
      # # trivyAdapterIndex defaults to "5"
      # # harborDatabaseIndex defaults to "0", but it can be configured to "6", this config is optional
      # # cacheLayerDatabaseIndex defaults to "0", but it can be configured to "7", this config is optional
      jobserviceDatabaseIndex: "1"
      registryDatabaseIndex: "2"
      trivyAdapterIndex: "5"
      # harborDatabaseIndex: "6"
      # cacheLayerDatabaseIndex: "7"
    external:
      # support redis, redis+sentinel
      # addr for redis: <host_redis>:<port_redis>
      # addr for redis+sentinel: <host_sentinel1>:<port_sentinel1>,<host_sentinel2>:<port_sentinel2>,<host_sentinel3>:<port_sentinel3>
      addr: "192.168.0.2:6379"
      # The name of the set of Redis instances to monitor, it must be set to support redis+sentinel
      sentinelMasterSet: ""
      # TLS configuration for redis connection
      # only server-authentication is supported, mTLS for redis connection is not supported
      # tls connection will be disable by default
      # Once `tlsOptions.enable` set as true, tls/ssl connection will be used for redis
      # Please set the `caBundleSecretName` in this configuration file which conatins redis server rootCA if it is self-signed.
      # The secret must contain keys named "ca.crt" which will be injected into the trust store
      tlsOptions:
        enable: false
      # The "coreDatabaseIndex" must be "0" as the library Harbor
      # used doesn't support configuring it
      # harborDatabaseIndex defaults to "0", but it can be configured to "6", this config is optional
      # cacheLayerDatabaseIndex defaults to "0", but it can be configured to "7", this config is optional
      coreDatabaseIndex: "0"
      jobserviceDatabaseIndex: "1"
      registryDatabaseIndex: "2"
      trivyAdapterIndex: "5"
      # harborDatabaseIndex: "6"
      # cacheLayerDatabaseIndex: "7"
      # username field can be an empty string, and it will be authenticated against the default user
      username: ""
      password: ""
      # If using existingSecret, the key must be REDIS_PASSWORD, if ACL mode enabled, also inlcudes data of username, the keys must be REDIS_USERNAME
      existingSecret: ""
    ## Additional deployment annotations
    podAnnotations: {}
    ## Additional deployment labels
    podLabels: {}

# MinIO subchart configuration
minio:
  enabled: false
  mode: standalone
  rootUser: "minioadmin"
  rootPassword: "minioadmin"
  replicas: 1
  resources:
    requests:
      memory: 2Gi
  buckets:
    - name: daytona
      policy: none
      purge: false
      versioning: false
      objectlocking: false
  persistence:
    enabled: true
    size: 8Gi
  service:
    type: ClusterIP
    port: 9000
  consoleService:
    type: ClusterIP
    port: 9001

# PostgreSQL subchart
postgresql:
  enabled: true
  global:
    security:
      allowInsecureImages: true
  image:
    registry: docker.io
    repository: bitnamilegacy/postgresql
    tag: 17.6.0-debian-12-r0
  auth:
    postgresPassword: "pass"
    username: "user"
    password: "pass"
    database: "daytona"
  primary:
    persistence:
      enabled: true
      size: 8Gi
